{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fashion MNIST data is available directly in the tf.keras datasets API. You load it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling load_data on this object will give you two sets of two lists, these will be the training and testing values for the graphics that contain the clothing items and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does these values look like? Let's print a training image, and a training label to see...Experiment with different indices in the array. For example, also take a look at index 42...that's a a different boot than the one at index 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[42])\n",
    "print(training_labels[42])\n",
    "print(training_images[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that all of the values in the number are between 0 and 255. If we are training a neural network, for various reasons it's easier if we treat all values as between 0 and 1, a process called 'normalizing'...and fortunately in Python it's easy to normalize a list like this without looping. You do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you might be wondering why there are 2 sets...training and testing. The idea is to have 1 set of data for training, and then another set of data...that the model hasn't yet seen...to see how good it would be at classifying values. After all, when you're done, you're going to want to try it out with data that it hadn't previously seen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now design the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to do, now the model is defined, is to actually build it. You do this by compiling it with an optimizer and loss function, then you train it by calling *model.fit * asking it to fit your training data to your training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4982 - accuracy: 0.8238\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3787 - accuracy: 0.8632\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3405 - accuracy: 0.8758\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3167 - accuracy: 0.8833\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2967 - accuracy: 0.8910\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2849 - accuracy: 0.8939\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2698 - accuracy: 0.8989\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2573 - accuracy: 0.9043\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2484 - accuracy: 0.9071\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2411 - accuracy: 0.9097s - loss: 0.2403 - accura\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2322 - accuracy: 0.9136\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2232 - accuracy: 0.9158\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2148 - accuracy: 0.9191\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2084 - accuracy: 0.9220\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2034 - accuracy: 0.9237\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1992 - accuracy: 0.9258\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1927 - accuracy: 0.9268\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1864 - accuracy: 0.9294\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.1813 - accuracy: 0.9317\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1765 - accuracy: 0.9338\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1733 - accuracy: 0.9347\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1694 - accuracy: 0.9363\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1657 - accuracy: 0.9378\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.1614 - accuracy: 0.9401\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.1605 - accuracy: 0.9392\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.1562 - accuracy: 0.9410\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.1514 - accuracy: 0.9428\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.1477 - accuracy: 0.9441\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.1448 - accuracy: 0.9466s\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.1434 - accuracy: 0.9455\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.1361 - accuracy: 0.9490\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1350 - accuracy: 0.9492\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.1334 - accuracy: 0.9498\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.1304 - accuracy: 0.9513\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.1276 - accuracy: 0.9529\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1264 - accuracy: 0.9528\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.1236 - accuracy: 0.9536\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.1219 - accuracy: 0.9543\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1175 - accuracy: 0.9554\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.1157 - accuracy: 0.9569s - l\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.1153 - accuracy: 0.9566\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.1131 - accuracy: 0.9571\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1104 - accuracy: 0.9582\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1088 - accuracy: 0.9594\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.1068 - accuracy: 0.9600s - loss: 0.106\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1046 - accuracy: 0.9608\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.1039 - accuracy: 0.9602\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.1016 - accuracy: 0.9621\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0981 - accuracy: 0.9637\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0984 - accuracy: 0.9635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x155fa8a58>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it's done training -- you should see an accuracy value at the end of the final epoch. It might look something like 0.9098. This tells you that your neural network is about 91% accurate in classifying the training data. I.E., it figured out a pattern match between the image and the labels that worked 91% of the time. Not great, but not bad considering it was only trained for 5 epochs and done quite quickly.\n",
    "\n",
    "But how would it work with unseen data? That's why we have the test images. We can call model.evaluate, and pass in the two sets, and it will report back the loss for each. Let's give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.5103 - accuracy: 0.8871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5103398943245411, 0.8871]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1297822e-11 3.9974056e-19 2.2817124e-13 4.2708774e-11 1.2814021e-10 2.2192014e-06 1.0739012e-14 1.8391546e-04 2.6771633e-14 9.9981385e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.1993 - accuracy: 0.9409\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0810 - accuracy: 0.9754\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0536 - accuracy: 0.9828\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0368 - accuracy: 0.9880\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0273 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x137126940>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 49us/sample - loss: 0.0646 - accuracy: 0.9808\n",
      "[7.1807116e-10 2.0543176e-09 1.0124467e-07 1.1804252e-06 3.0006539e-14 3.7899448e-09 1.0848844e-14 9.9999857e-01 3.6570447e-09 1.5370540e-07]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
